{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'psycopg2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-597404e1e8d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdivision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpsycopg2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'psycopg2'"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "#import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import  LabelBinarizer\n",
    "\n",
    "import csv as csv\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.cross_validation import KFold, StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import  LabelBinarizer\n",
    "#from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import  LabelBinarizer\n",
    "#from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.base import TransformerMixin\n",
    "from scipy.sparse import coo_matrix\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn import preprocessing\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "def connect():\n",
    "    hostname = '********'\n",
    "    username = '********'\n",
    "    password = '********'\n",
    "    database = '********'\n",
    "    myConnection = psycopg2.connect( host=hostname, user=username, password=password, dbname=database )\n",
    "    return myConnection\n",
    "\n",
    "def replace_dash(df,col):\n",
    "    institut=[]\n",
    "    for instit in df[col]:\n",
    "        instit\n",
    "        ins = str(instit).replace(\"-\", \"_\")\n",
    "        #print(ins)\n",
    "        institut.append(ins)\n",
    "    df[col]=institut\n",
    "    return df\n",
    "\n",
    "\n",
    "def replace_space(df,col):\n",
    "    institut=[]\n",
    "    for instit in df[col]:\n",
    "        instit\n",
    "        ins = str(instit).replace(\" \", \"_\")\n",
    "        #print(ins)\n",
    "        institut.append(ins)\n",
    "    df[col]=institut\n",
    "    return df\n",
    "\n",
    "\n",
    "cvartistquery =\"select a.id ********\"\n",
    "\n",
    "conn = connect()\n",
    "cvartist = pd.read_sql_query(cvartistquery, conn)\n",
    "cvartist.head()\n",
    "\n",
    "artist_event = replace_dash(cvartist,'instit_normalized_name')\n",
    "artist_event = replace_dash(artist_event,'normalized_city_abbreviation')\n",
    "artist_event=replace_space(artist_event,'practicing_country')\n",
    "\n",
    "artist_event.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
